name: Update Crypto Dataset

on:
  schedule:
    - cron: '0 0 * * 0'  # Run every Sunday at midnight UTC
  workflow_dispatch:  # Allow manual trigger

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas yfinance pycoingecko kaggle
      
      - name: Clean old data
        run: |
          rm -rf crypto_data
      
      - name: Create Kaggle config (before running script)
        run: |
          mkdir -p ~/.kaggle
          echo '{"username":"${{ secrets.KAGGLE_USERNAME }}","key":"${{ secrets.KAGGLE_KEY }}"}' > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json
      
      - name: Run data collection script
        run: python main.py
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
      
      - name: Verify dataset structure
        run: |
          echo "=== Verifying dataset structure ==="
          ls -la crypto_data/
          echo ""
          echo "=== Contents of crypto_top100 folder ==="
          ls -la crypto_data/crypto_top100/ | head -n 20
          echo ""
          echo "=== Checking crypto_directory.csv ==="
          head -n 10 crypto_data/crypto_directory.csv
          echo ""
          echo "=== Total CSV files in crypto_top100 ==="
          ls crypto_data/crypto_top100/*.csv | wc -l
      
      - name: Check if dataset exists
        id: check_dataset
        run: |
          if kaggle datasets status ${{ secrets.KAGGLE_USERNAME }}/top-100-cryptocurrency-historical-data 2>/dev/null; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
      
      - name: Validate metadata JSON
        run: |
          cd crypto_data
          echo "=== Checking dataset-metadata.json ==="
          if [ -f "dataset-metadata.json" ]; then
            echo "✓ Metadata file exists"
            cat dataset-metadata.json | jq '.' > /dev/null && echo "✓ Valid JSON" || echo "✗ Invalid JSON"
            echo ""
            echo "=== Metadata preview (first 30 lines) ==="
            cat dataset-metadata.json | head -n 30
          else
            echo "✗ Metadata file not found!"
            exit 1
          fi
      
      - name: Create or Update Kaggle dataset
        run: |
          cd crypto_data
          
          if [ "${{ steps.check_dataset.outputs.exists }}" = "true" ]; then
            echo "Updating existing dataset..."
            kaggle datasets version -p . -m "Automated weekly update on $(date +'%Y-%m-%d')" -r zip
          else
            echo "Creating new dataset..."
            kaggle datasets create -p . -r zip
          fi
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
      
      - name: Upload logs and data (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: error-logs-${{ github.run_number }}
          path: |
            crypto_data/
            *.log
          retention-days: 7
      
      - name: Summary
        if: success()
        run: |
          echo "=== ✅ Dataset Update Successful ==="
          echo "Dataset: ${{ secrets.KAGGLE_USERNAME }}/top-100-cryptocurrency-historical-data"
          echo "Date: $(date +'%Y-%m-%d %H:%M:%S UTC')"
          echo "Status: ${{ steps.check_dataset.outputs.exists == 'true' && 'Updated' || 'Created' }}"
          echo ""
          cd crypto_data
          echo "Files uploaded:"
          echo "- crypto_directory.csv (1 file)"
          echo "- crypto_top100/ ($(ls crypto_top100/*.csv 2>/dev/null | wc -l) CSV files)"
          echo "- dataset-metadata.json (1 file)"